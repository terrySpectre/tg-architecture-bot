import torch
from torchvision import transforms
from PIL import Image
from telegram import Update
from telegram.ext import ApplicationBuilder, CommandHandler, MessageHandler, ContextTypes, filters
import io
import torchvision.models as models

# === –ù–∞—Å—Ç—Ä–æ–π–∫–∏ –º–æ–¥–µ–ª–∏ ===
NUM_CLASSES = 25
MODEL_PATH = "efficientnet_finetuned.pth"

# === –ü—Ä–æ–≤–µ—Ä–∫–∞ —É—Å—Ç—Ä–æ–π—Å—Ç–≤–∞ ===
device = torch.device("cuda" if torch.cuda.is_available() else "cpu")

# === –°–æ–∑–¥–∞–Ω–∏–µ –∏ –∑–∞–≥—Ä—É–∑–∫–∞ –º–æ–¥–µ–ª–∏ –±–µ–∑ –ø—Ä–µ–¥–æ–±—É—á–µ–Ω–Ω—ã—Ö –≤–µ—Å–æ–≤ ===
model = models.efficientnet_b0(weights=None)  # –ù–ï –∑–∞–≥—Ä—É–∂–∞–µ–º pretrained

# –ó–∞–º–µ–Ω—è–µ–º –ø–æ—Å–ª–µ–¥–Ω–∏–π —Å–ª–æ–π –∫–ª–∞—Å—Å–∏—Ñ–∏–∫–∞—Ç–æ—Ä–∞
model.classifier = torch.nn.Sequential(
    torch.nn.Dropout(p=0.2),
    torch.nn.Linear(model.classifier[1].in_features, NUM_CLASSES)
)

model.load_state_dict(torch.load(MODEL_PATH, map_location=device), strict=False)  # –ó–∞–≥—Ä—É–∂–∞–µ–º –Ω–∞ –ø—Ä–∞–≤–∏–ª—å–Ω–æ–µ —É—Å—Ç—Ä–æ–π—Å—Ç–≤–æ
model = model.to(device)
model.eval()

# === –ü—Ä–µ–æ–±—Ä–∞–∑–æ–≤–∞–Ω–∏—è ===
transform = transforms.Compose([
    transforms.Resize((224, 224)),
    transforms.ToTensor(),
    transforms.Normalize(mean=[0.485, 0.456, 0.406], std=[0.229, 0.224, 0.225])  # –ù–æ—Ä–º–∞–ª–∏–∑–∞—Ü–∏—è –¥–ª—è EfficientNet
])

# === –ù–∞–∑–≤–∞–Ω–∏—è –∫–ª–∞—Å—Å–æ–≤ ===
idx_to_class = {
    0: "Achaemenid architecture", 1: "American Foursquare architecture", 2: "American craftsman style",
    3: "Ancient Egyptian architecture", 4: "Art Deco architecture", 5: "Art Nouveau architecture",
    6: "Baroque architecture", 7: "Bauhaus architecture", 8: "Beaux-Arts architecture",
    9: "Byzantine architecture", 10: "Chicago school architecture", 11: "Colonial architecture",
    12: "Deconstructivism", 13: "Edwardian architecture", 14: "Georgian architecture",
    15: "Gothic architecture", 16: "Greek Revival architecture", 17: "International style",
    18: "Novelty architecture", 19: "Palladian architecture", 20: "Postmodern architecture",
    21: "Queen Anne architecture", 22: "Romanesque architecture", 23: "Russian Revival architecture",
    24: "Tudor Revival architecture"
}

# === –ö–æ–º–∞–Ω–¥—ã ===
async def start(update: Update, context: ContextTypes.DEFAULT_TYPE):
    await update.message.reply_text("–ü—Ä–∏–≤–µ—Ç! –û—Ç–ø—Ä–∞–≤—å –º–Ω–µ —Ñ–æ—Ç–æ –∑–¥–∞–Ω–∏—è, –∏ —è –æ–ø—Ä–µ–¥–µ–ª—é –∞—Ä—Ö–∏—Ç–µ–∫—Ç—É—Ä–Ω—ã–π —Å—Ç–∏–ª—å üèõÔ∏è")

async def handle_photo(update: Update, context: ContextTypes.DEFAULT_TYPE):
    photo = update.message.photo[-1]
    file = await photo.get_file()
    image_stream = io.BytesIO()
    await file.download_to_memory(out=image_stream)
    image_stream.seek(0)

    # –û—Ç–∫—Ä—ã–≤–∞–µ–º –∏–∑–æ–±—Ä–∞–∂–µ–Ω–∏–µ –∏ –≤—ã–ø–æ–ª–Ω—è–µ–º –ø—Ä–µ–æ–±—Ä–∞–∑–æ–≤–∞–Ω–∏—è
    image = Image.open(image_stream).convert('RGB')
    input_tensor = transform(image).unsqueeze(0).to(device)  # –ü—Ä–µ–æ–±—Ä–∞–∑—É–µ–º –∏–∑–æ–±—Ä–∞–∂–µ–Ω–∏–µ –∏ –ø–µ—Ä–µ–Ω–æ—Å–∏–º –Ω–∞ —É—Å—Ç—Ä–æ–π—Å—Ç–≤–æ

    # –ü–æ–ª—É—á–∞–µ–º –ø—Ä–µ–¥—Å–∫–∞–∑–∞–Ω–∏–µ
    with torch.no_grad():
        outputs = model(input_tensor)
        _, predicted = torch.max(outputs, 1)

    # –ü–æ–ª—É—á–∞–µ–º –Ω–∞–∑–≤–∞–Ω–∏–µ –∫–ª–∞—Å—Å–∞
    predicted_class = idx_to_class.get(predicted.item(), "–ù–µ–∏–∑–≤–µ—Å—Ç–Ω–æ")
    await update.message.reply_text(f"üì∏ –ü—Ä–µ–¥—Å–∫–∞–∑–∞–Ω–Ω—ã–π –∞—Ä—Ö–∏—Ç–µ–∫—Ç—É—Ä–Ω—ã–π —Å—Ç–∏–ª—å: {predicted_class}")

# === –ó–∞–ø—É—Å–∫ ===
def main():
    TOKEN = "7854664139:AAGjNjdmjZPGv6XbqqNnA07x-6aBVfBa9UY"  # –í–∞—à —Ç–æ–∫–µ–Ω
    app = ApplicationBuilder().token(TOKEN).build()

    app.add_handler(CommandHandler("start", start))
    app.add_handler(MessageHandler(filters.PHOTO, handle_photo))

    app.run_polling()

if __name__ == '__main__':
    main()
